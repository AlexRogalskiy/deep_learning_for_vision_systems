{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 6 # for resnet50\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "depth = n * 6 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'resnet50'\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same',\n",
    "                  kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    \n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet(input_shape=input_shape, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 32, 32, 16)   448         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 32, 32, 16)   64          conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 32, 32, 16)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 32, 32, 16)   2320        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 32, 32, 16)   64          conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 32, 32, 16)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 32, 32, 16)   2320        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 32, 32, 16)   64          conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 32, 32, 16)   0           activation_161[0][0]             \n",
      "                                                                 batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 32, 32, 16)   0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 32, 32, 16)   2320        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 32, 32, 16)   64          conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 32, 32, 16)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 32, 32, 16)   2320        activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 32, 32, 16)   64          conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 32, 32, 16)   0           activation_163[0][0]             \n",
      "                                                                 batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 32, 32, 16)   0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 32, 32, 16)   2320        activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 32, 32, 16)   64          conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 32, 32, 16)   0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 32, 32, 16)   2320        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 32, 32, 16)   64          conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 32, 32, 16)   0           activation_165[0][0]             \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 32, 32, 16)   0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 32, 32, 16)   2320        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 32, 32, 16)   64          conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 32, 32, 16)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 32, 32, 16)   2320        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 32, 32, 16)   64          conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 32, 32, 16)   0           activation_167[0][0]             \n",
      "                                                                 batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 32, 32, 16)   0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 32, 32, 16)   2320        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 32, 32, 16)   64          conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 32, 32, 16)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 32, 32, 16)   2320        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 32, 32, 16)   64          conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 32, 32, 16)   0           activation_169[0][0]             \n",
      "                                                                 batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 32, 32, 16)   0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 32, 32, 16)   2320        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 32, 32, 16)   64          conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 32, 32, 16)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 32, 32, 16)   2320        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 32, 32, 16)   64          conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 32, 32, 16)   0           activation_171[0][0]             \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 32, 32, 16)   0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 16, 16, 32)   4640        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 16, 16, 32)   128         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 16, 16, 32)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 16, 16, 32)   9248        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 16, 16, 32)   544         activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 16, 16, 32)   128         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 16, 16, 32)   0           conv2d_185[0][0]                 \n",
      "                                                                 batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 16, 16, 32)   0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 16, 16, 32)   9248        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 16, 16, 32)   128         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 16, 16, 32)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 16, 16, 32)   9248        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 16, 16, 32)   128         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 16, 16, 32)   0           activation_175[0][0]             \n",
      "                                                                 batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 16, 16, 32)   0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 16, 16, 32)   9248        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 16, 16, 32)   128         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 16, 16, 32)   0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 16, 16, 32)   9248        activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 16, 16, 32)   128         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 16, 16, 32)   0           activation_177[0][0]             \n",
      "                                                                 batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 16, 16, 32)   0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 16, 16, 32)   9248        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 16, 16, 32)   128         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 16, 16, 32)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 16, 16, 32)   9248        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 16, 16, 32)   128         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 16, 16, 32)   0           activation_179[0][0]             \n",
      "                                                                 batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 16, 16, 32)   0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 16, 16, 32)   9248        activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 16, 16, 32)   128         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 16, 16, 32)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 32)   9248        activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 16, 16, 32)   128         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 16, 16, 32)   0           activation_181[0][0]             \n",
      "                                                                 batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 16, 16, 32)   0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 32)   9248        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 16, 16, 32)   128         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 16, 16, 32)   0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 32)   9248        activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 16, 16, 32)   128         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 16, 16, 32)   0           activation_183[0][0]             \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 16, 16, 32)   0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 8, 8, 64)     18496       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 64)     256         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 64)     0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 8, 8, 64)     36928       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 8, 8, 64)     2112        activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 64)     256         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 8, 8, 64)     0           conv2d_198[0][0]                 \n",
      "                                                                 batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 64)     0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 8, 8, 64)     36928       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 64)     256         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 64)     0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 64)     36928       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 64)     256         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 8, 8, 64)     0           activation_187[0][0]             \n",
      "                                                                 batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 64)     0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 64)     36928       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 8, 8, 64)     256         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 64)     0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 64)     36928       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 8, 8, 64)     256         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 8, 8, 64)     0           activation_189[0][0]             \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 64)     0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 8, 8, 64)     36928       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 8, 8, 64)     256         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 64)     0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 8, 8, 64)     36928       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 8, 8, 64)     256         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 8, 8, 64)     0           activation_191[0][0]             \n",
      "                                                                 batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 64)     0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 8, 8, 64)     36928       activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 8, 8, 64)     256         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 64)     0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 64)     36928       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 8, 8, 64)     256         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 8, 8, 64)     0           activation_193[0][0]             \n",
      "                                                                 batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 8, 8, 64)     0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 64)     36928       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 8, 8, 64)     256         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 8, 8, 64)     0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 64)     36928       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 8, 8, 64)     256         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 8, 8, 64)     0           activation_195[0][0]             \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 8, 8, 64)     0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           650         flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 568,106\n",
      "Trainable params: 565,386\n",
      "Non-trainable params: 2,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdeeplearning",
   "language": "python",
   "name": "tfdeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
