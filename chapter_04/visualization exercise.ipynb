{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a toy dataset of only two features and four label classes\n",
    "X, y = make_blobs(n_samples=1000, centers=4, n_features=2, cluster_std=2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 0, 1, 2, 3, 2, 1, 0, 1, 0, 0, 2, 2, 3, 2, 1, 3, 0,\n",
       "       0, 3, 1, 3, 3, 3, 0, 2, 0, 0, 2, 3, 1, 0, 1, 2, 2, 1, 3, 3, 1, 2,\n",
       "       3, 0, 0, 1, 1, 0, 0, 3, 0, 3, 2, 3, 3, 0, 2, 1, 3, 1, 3, 0, 1, 3,\n",
       "       0, 1, 3, 0, 2, 1, 3, 3, 2, 2, 1, 1, 3, 2, 3, 1, 2, 2, 0, 2, 3, 3,\n",
       "       1, 2, 3, 0, 2, 0, 1, 2, 2, 0, 3, 0, 3, 3, 3, 1, 1, 2, 2, 1, 0, 3,\n",
       "       0, 3, 1, 3, 0, 0, 0, 0, 2, 2, 0, 3, 0, 2, 1, 2, 3, 0, 1, 0, 2, 0,\n",
       "       0, 0, 1, 0, 3, 2, 1, 1, 3, 1, 0, 2, 3, 3, 1, 1, 1, 3, 1, 1, 3, 0,\n",
       "       1, 1, 1, 3, 2, 2, 0, 2, 1, 2, 0, 2, 0, 1, 1, 2, 1, 3, 3, 0, 3, 2,\n",
       "       1, 2, 2, 3, 3, 0, 2, 2, 2, 1, 2, 1, 0, 0, 1, 3, 2, 2, 1, 0, 3, 2,\n",
       "       3, 3, 3, 3, 3, 2, 3, 1, 2, 3, 0, 2, 0, 2, 3, 3, 0, 3, 0, 3, 0, 3,\n",
       "       2, 3, 3, 0, 2, 1, 1, 1, 3, 3, 2, 1, 3, 3, 3, 3, 2, 0, 2, 3, 1, 1,\n",
       "       3, 2, 0, 0, 2, 0, 2, 1, 0, 3, 1, 1, 1, 0, 1, 2, 3, 1, 2, 1, 2, 2,\n",
       "       2, 0, 2, 0, 3, 2, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 3, 2, 3, 1, 3, 0,\n",
       "       2, 0, 2, 3, 2, 1, 3, 1, 2, 1, 2, 0, 3, 0, 3, 0, 2, 1, 1, 2, 0, 1,\n",
       "       1, 0, 2, 3, 3, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1, 0, 1, 3, 2, 1, 1, 1,\n",
       "       2, 1, 1, 3, 3, 3, 0, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 3, 2, 0, 2, 1,\n",
       "       1, 0, 2, 1, 2, 1, 0, 0, 1, 3, 3, 0, 1, 2, 2, 0, 0, 0, 3, 2, 0, 1,\n",
       "       0, 3, 3, 2, 3, 0, 2, 0, 3, 3, 3, 1, 2, 0, 3, 1, 2, 3, 3, 0, 0, 2,\n",
       "       0, 3, 3, 1, 3, 1, 0, 2, 3, 1, 1, 1, 1, 0, 0, 1, 3, 2, 2, 3, 0, 2,\n",
       "       2, 0, 2, 2, 2, 3, 0, 0, 0, 3, 1, 1, 3, 2, 1, 2, 2, 1, 1, 0, 3, 2,\n",
       "       0, 3, 1, 2, 2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1, 3, 1, 1, 1, 0, 3, 2,\n",
       "       2, 2, 2, 0, 0, 3, 2, 2, 0, 3, 0, 0, 2, 3, 0, 1, 1, 0, 3, 1, 0, 3,\n",
       "       2, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 3, 1, 1, 1, 1, 1, 0,\n",
       "       0, 2, 1, 3, 1, 0, 3, 0, 0, 3, 2, 1, 1, 0, 3, 2, 2, 1, 3, 2, 1, 1,\n",
       "       3, 2, 3, 1, 3, 2, 3, 2, 2, 3, 1, 2, 0, 3, 2, 2, 0, 0, 3, 3, 2, 2,\n",
       "       2, 1, 3, 0, 2, 2, 3, 2, 3, 2, 3, 0, 3, 1, 0, 1, 1, 3, 3, 3, 2, 3,\n",
       "       3, 1, 0, 2, 3, 3, 0, 0, 0, 1, 3, 0, 3, 0, 0, 3, 1, 1, 3, 3, 2, 1,\n",
       "       2, 3, 3, 3, 1, 3, 3, 2, 0, 2, 1, 0, 1, 3, 0, 2, 2, 2, 3, 3, 0, 0,\n",
       "       3, 0, 2, 2, 0, 0, 0, 3, 3, 1, 1, 3, 3, 1, 0, 3, 0, 1, 1, 0, 2, 3,\n",
       "       0, 3, 1, 3, 0, 2, 1, 3, 3, 3, 0, 1, 3, 0, 0, 2, 3, 2, 0, 3, 1, 2,\n",
       "       3, 0, 3, 3, 0, 1, 2, 1, 2, 2, 2, 1, 3, 2, 2, 1, 0, 3, 2, 3, 2, 1,\n",
       "       1, 2, 0, 3, 3, 3, 1, 1, 1, 2, 1, 0, 3, 2, 0, 1, 2, 1, 0, 0, 1, 1,\n",
       "       1, 0, 3, 3, 0, 1, 1, 1, 2, 0, 3, 2, 1, 2, 1, 2, 0, 1, 1, 1, 0, 2,\n",
       "       2, 3, 1, 2, 1, 3, 2, 3, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 1, 0, 3,\n",
       "       0, 0, 2, 0, 3, 1, 0, 3, 1, 2, 1, 1, 0, 1, 2, 2, 1, 1, 3, 1, 2, 1,\n",
       "       0, 0, 3, 2, 1, 0, 1, 0, 3, 0, 3, 0, 0, 3, 1, 1, 3, 2, 3, 1, 2, 3,\n",
       "       1, 2, 3, 2, 2, 3, 1, 1, 1, 3, 0, 0, 2, 2, 1, 1, 0, 3, 2, 0, 0, 1,\n",
       "       3, 2, 2, 0, 3, 3, 3, 0, 3, 2, 2, 2, 0, 2, 2, 1, 1, 3, 2, 0, 0, 3,\n",
       "       2, 2, 3, 0, 2, 0, 1, 3, 2, 1, 1, 1, 2, 3, 0, 3, 3, 2, 0, 2, 1, 3,\n",
       "       0, 3, 2, 0, 1, 0, 1, 2, 2, 1, 1, 2, 0, 1, 0, 2, 1, 3, 2, 2, 2, 3,\n",
       "       3, 0, 0, 1, 3, 1, 1, 1, 2, 2, 2, 1, 0, 0, 3, 2, 2, 3, 3, 1, 0, 2,\n",
       "       1, 3, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 0, 1, 2, 3, 0, 3, 1, 2, 2, 2,\n",
       "       0, 0, 1, 0, 0, 3, 2, 2, 0, 3, 1, 3, 2, 0, 0, 1, 2, 3, 3, 2, 1, 3,\n",
       "       0, 1, 1, 0, 0, 1, 3, 2, 1, 1, 3, 3, 2, 0, 3, 0, 3, 2, 2, 0, 3, 3,\n",
       "       1, 0, 0, 2, 1, 3, 3, 0, 2, 3, 1, 0, 1, 1, 2, 0, 3, 2, 0, 1, 0, 0,\n",
       "       3, 0, 1, 0, 3, 1, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the label (y) before one-hot encoding\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode output variable\n",
    "y = to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2) (800, 2)\n"
     ]
    }
   ],
   "source": [
    "# split into 80% training data and 20% test data \n",
    "# note that we did not create a validation dataset in this example for simplicity\n",
    "n_train = 200\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                75        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 104       \n",
      "=================================================================\n",
      "Total params: 179\n",
      "Trainable params: 179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# develop the baseline model architecture\n",
    "# here we are building a very simple, two-layer network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax')) # four hidden units because we have 4 label classes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 800 samples\n",
      "Epoch 1/500\n",
      "200/200 [==============================] - 0s 554us/step - loss: 1.7862 - accuracy: 0.2500 - val_loss: 1.7178 - val_accuracy: 0.2663\n",
      "Epoch 2/500\n",
      "200/200 [==============================] - 0s 91us/step - loss: 1.6395 - accuracy: 0.2650 - val_loss: 1.5710 - val_accuracy: 0.2763\n",
      "Epoch 3/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 1.4964 - accuracy: 0.2850 - val_loss: 1.4395 - val_accuracy: 0.2788\n",
      "Epoch 4/500\n",
      "200/200 [==============================] - 0s 90us/step - loss: 1.3691 - accuracy: 0.2950 - val_loss: 1.3193 - val_accuracy: 0.2825\n",
      "Epoch 5/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 1.2535 - accuracy: 0.3650 - val_loss: 1.2095 - val_accuracy: 0.4150\n",
      "Epoch 6/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 1.1510 - accuracy: 0.4850 - val_loss: 1.1122 - val_accuracy: 0.4787\n",
      "Epoch 7/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 1.0593 - accuracy: 0.5400 - val_loss: 1.0300 - val_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.9850 - accuracy: 0.5500 - val_loss: 0.9592 - val_accuracy: 0.5263\n",
      "Epoch 9/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.9197 - accuracy: 0.5900 - val_loss: 0.9017 - val_accuracy: 0.5537\n",
      "Epoch 10/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.8656 - accuracy: 0.6050 - val_loss: 0.8551 - val_accuracy: 0.5763\n",
      "Epoch 11/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.8187 - accuracy: 0.6300 - val_loss: 0.8177 - val_accuracy: 0.6137\n",
      "Epoch 12/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.7847 - accuracy: 0.6650 - val_loss: 0.7860 - val_accuracy: 0.6538\n",
      "Epoch 13/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.7546 - accuracy: 0.7000 - val_loss: 0.7609 - val_accuracy: 0.6837\n",
      "Epoch 14/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.7289 - accuracy: 0.7250 - val_loss: 0.7420 - val_accuracy: 0.6913\n",
      "Epoch 15/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.7097 - accuracy: 0.7450 - val_loss: 0.7274 - val_accuracy: 0.7000\n",
      "Epoch 16/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.6940 - accuracy: 0.7500 - val_loss: 0.7151 - val_accuracy: 0.7100\n",
      "Epoch 17/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.6808 - accuracy: 0.7500 - val_loss: 0.7050 - val_accuracy: 0.7100\n",
      "Epoch 18/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.6685 - accuracy: 0.7500 - val_loss: 0.6961 - val_accuracy: 0.7163\n",
      "Epoch 19/500\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.6588 - accuracy: 0.7500 - val_loss: 0.6884 - val_accuracy: 0.7175\n",
      "Epoch 20/500\n",
      "200/200 [==============================] - 0s 90us/step - loss: 0.6500 - accuracy: 0.7500 - val_loss: 0.6821 - val_accuracy: 0.7188\n",
      "Epoch 21/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.6425 - accuracy: 0.7500 - val_loss: 0.6752 - val_accuracy: 0.7237\n",
      "Epoch 22/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.6346 - accuracy: 0.7700 - val_loss: 0.6688 - val_accuracy: 0.7237\n",
      "Epoch 23/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.6283 - accuracy: 0.7600 - val_loss: 0.6641 - val_accuracy: 0.7262\n",
      "Epoch 24/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.6226 - accuracy: 0.7750 - val_loss: 0.6587 - val_accuracy: 0.7237\n",
      "Epoch 25/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.6164 - accuracy: 0.7750 - val_loss: 0.6537 - val_accuracy: 0.7262\n",
      "Epoch 26/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.6111 - accuracy: 0.7750 - val_loss: 0.6485 - val_accuracy: 0.7287\n",
      "Epoch 27/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.6067 - accuracy: 0.7700 - val_loss: 0.6436 - val_accuracy: 0.7300\n",
      "Epoch 28/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.6017 - accuracy: 0.7700 - val_loss: 0.6400 - val_accuracy: 0.7300\n",
      "Epoch 29/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5980 - accuracy: 0.7650 - val_loss: 0.6368 - val_accuracy: 0.7300\n",
      "Epoch 30/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5934 - accuracy: 0.7750 - val_loss: 0.6334 - val_accuracy: 0.7300\n",
      "Epoch 31/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5890 - accuracy: 0.7750 - val_loss: 0.6301 - val_accuracy: 0.7325\n",
      "Epoch 32/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.5852 - accuracy: 0.7800 - val_loss: 0.6268 - val_accuracy: 0.7350\n",
      "Epoch 33/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5814 - accuracy: 0.7850 - val_loss: 0.6239 - val_accuracy: 0.7350\n",
      "Epoch 34/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.5787 - accuracy: 0.7850 - val_loss: 0.6220 - val_accuracy: 0.7337\n",
      "Epoch 35/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.5753 - accuracy: 0.7850 - val_loss: 0.6184 - val_accuracy: 0.7362\n",
      "Epoch 36/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.5715 - accuracy: 0.7900 - val_loss: 0.6158 - val_accuracy: 0.7375\n",
      "Epoch 37/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.5683 - accuracy: 0.7850 - val_loss: 0.6140 - val_accuracy: 0.7362\n",
      "Epoch 38/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.5653 - accuracy: 0.7900 - val_loss: 0.6111 - val_accuracy: 0.7387\n",
      "Epoch 39/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5621 - accuracy: 0.7900 - val_loss: 0.6092 - val_accuracy: 0.7387\n",
      "Epoch 40/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.5592 - accuracy: 0.7900 - val_loss: 0.6077 - val_accuracy: 0.7387\n",
      "Epoch 41/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5562 - accuracy: 0.7950 - val_loss: 0.6062 - val_accuracy: 0.7425\n",
      "Epoch 42/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.5541 - accuracy: 0.7900 - val_loss: 0.6038 - val_accuracy: 0.7400\n",
      "Epoch 43/500\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.5510 - accuracy: 0.7900 - val_loss: 0.6012 - val_accuracy: 0.7437\n",
      "Epoch 44/500\n",
      "200/200 [==============================] - 0s 92us/step - loss: 0.5487 - accuracy: 0.7900 - val_loss: 0.5990 - val_accuracy: 0.7450\n",
      "Epoch 45/500\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.5461 - accuracy: 0.7900 - val_loss: 0.5970 - val_accuracy: 0.7462\n",
      "Epoch 46/500\n",
      "200/200 [==============================] - 0s 92us/step - loss: 0.5439 - accuracy: 0.7950 - val_loss: 0.5954 - val_accuracy: 0.7437\n",
      "Epoch 47/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.5416 - accuracy: 0.7950 - val_loss: 0.5946 - val_accuracy: 0.7450\n",
      "Epoch 48/500\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.5390 - accuracy: 0.8000 - val_loss: 0.5915 - val_accuracy: 0.7475\n",
      "Epoch 49/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.5372 - accuracy: 0.7950 - val_loss: 0.5909 - val_accuracy: 0.7437\n",
      "Epoch 50/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.5350 - accuracy: 0.7950 - val_loss: 0.5870 - val_accuracy: 0.7475\n",
      "Epoch 51/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.5319 - accuracy: 0.8000 - val_loss: 0.5845 - val_accuracy: 0.7525\n",
      "Epoch 52/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5293 - accuracy: 0.7950 - val_loss: 0.5824 - val_accuracy: 0.7525\n",
      "Epoch 53/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.5274 - accuracy: 0.8050 - val_loss: 0.5810 - val_accuracy: 0.7513\n",
      "Epoch 54/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.5253 - accuracy: 0.8100 - val_loss: 0.5785 - val_accuracy: 0.7525\n",
      "Epoch 55/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.5231 - accuracy: 0.8100 - val_loss: 0.5779 - val_accuracy: 0.7538\n",
      "Epoch 56/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5209 - accuracy: 0.8050 - val_loss: 0.5757 - val_accuracy: 0.7550\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 73us/step - loss: 0.5188 - accuracy: 0.8050 - val_loss: 0.5740 - val_accuracy: 0.7563\n",
      "Epoch 58/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.5166 - accuracy: 0.8050 - val_loss: 0.5715 - val_accuracy: 0.7550\n",
      "Epoch 59/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5153 - accuracy: 0.8100 - val_loss: 0.5689 - val_accuracy: 0.7563\n",
      "Epoch 60/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.5141 - accuracy: 0.8100 - val_loss: 0.5690 - val_accuracy: 0.7563\n",
      "Epoch 61/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.5114 - accuracy: 0.8000 - val_loss: 0.5665 - val_accuracy: 0.7588\n",
      "Epoch 62/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.5099 - accuracy: 0.8000 - val_loss: 0.5631 - val_accuracy: 0.7613\n",
      "Epoch 63/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5086 - accuracy: 0.8050 - val_loss: 0.5609 - val_accuracy: 0.7625\n",
      "Epoch 64/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5064 - accuracy: 0.8100 - val_loss: 0.5610 - val_accuracy: 0.7588\n",
      "Epoch 65/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.5039 - accuracy: 0.8100 - val_loss: 0.5594 - val_accuracy: 0.7563\n",
      "Epoch 66/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.5025 - accuracy: 0.8100 - val_loss: 0.5580 - val_accuracy: 0.7588\n",
      "Epoch 67/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.5001 - accuracy: 0.8150 - val_loss: 0.5574 - val_accuracy: 0.7563\n",
      "Epoch 68/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.4989 - accuracy: 0.8150 - val_loss: 0.5556 - val_accuracy: 0.7575\n",
      "Epoch 69/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4971 - accuracy: 0.8150 - val_loss: 0.5551 - val_accuracy: 0.7600\n",
      "Epoch 70/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4952 - accuracy: 0.8250 - val_loss: 0.5535 - val_accuracy: 0.7625\n",
      "Epoch 71/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4936 - accuracy: 0.8200 - val_loss: 0.5516 - val_accuracy: 0.7638\n",
      "Epoch 72/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.4923 - accuracy: 0.8200 - val_loss: 0.5503 - val_accuracy: 0.7638\n",
      "Epoch 73/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4908 - accuracy: 0.8200 - val_loss: 0.5488 - val_accuracy: 0.7638\n",
      "Epoch 74/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4890 - accuracy: 0.8200 - val_loss: 0.5480 - val_accuracy: 0.7663\n",
      "Epoch 75/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4873 - accuracy: 0.8250 - val_loss: 0.5463 - val_accuracy: 0.7638\n",
      "Epoch 76/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4855 - accuracy: 0.8200 - val_loss: 0.5445 - val_accuracy: 0.7650\n",
      "Epoch 77/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.4840 - accuracy: 0.8250 - val_loss: 0.5432 - val_accuracy: 0.7650\n",
      "Epoch 78/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.4825 - accuracy: 0.8300 - val_loss: 0.5415 - val_accuracy: 0.7700\n",
      "Epoch 79/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4810 - accuracy: 0.8350 - val_loss: 0.5399 - val_accuracy: 0.7700\n",
      "Epoch 80/500\n",
      "200/200 [==============================] - 0s 69us/step - loss: 0.4795 - accuracy: 0.8350 - val_loss: 0.5394 - val_accuracy: 0.7688\n",
      "Epoch 81/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.4775 - accuracy: 0.8350 - val_loss: 0.5394 - val_accuracy: 0.7650\n",
      "Epoch 82/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.4769 - accuracy: 0.8300 - val_loss: 0.5396 - val_accuracy: 0.7650\n",
      "Epoch 83/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4755 - accuracy: 0.8350 - val_loss: 0.5383 - val_accuracy: 0.7650\n",
      "Epoch 84/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4738 - accuracy: 0.8300 - val_loss: 0.5379 - val_accuracy: 0.7675\n",
      "Epoch 85/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.4723 - accuracy: 0.8250 - val_loss: 0.5369 - val_accuracy: 0.7675\n",
      "Epoch 86/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4706 - accuracy: 0.8250 - val_loss: 0.5365 - val_accuracy: 0.7663\n",
      "Epoch 87/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.4697 - accuracy: 0.8350 - val_loss: 0.5362 - val_accuracy: 0.7663\n",
      "Epoch 88/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.4682 - accuracy: 0.8350 - val_loss: 0.5340 - val_accuracy: 0.7700\n",
      "Epoch 89/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4671 - accuracy: 0.8350 - val_loss: 0.5340 - val_accuracy: 0.7663\n",
      "Epoch 90/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4655 - accuracy: 0.8400 - val_loss: 0.5325 - val_accuracy: 0.7688\n",
      "Epoch 91/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4642 - accuracy: 0.8300 - val_loss: 0.5311 - val_accuracy: 0.7713\n",
      "Epoch 92/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4629 - accuracy: 0.8300 - val_loss: 0.5289 - val_accuracy: 0.7713\n",
      "Epoch 93/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4612 - accuracy: 0.8300 - val_loss: 0.5274 - val_accuracy: 0.7700\n",
      "Epoch 94/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4600 - accuracy: 0.8350 - val_loss: 0.5279 - val_accuracy: 0.7700\n",
      "Epoch 95/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.4590 - accuracy: 0.8400 - val_loss: 0.5269 - val_accuracy: 0.7688\n",
      "Epoch 96/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.4583 - accuracy: 0.8450 - val_loss: 0.5258 - val_accuracy: 0.7713\n",
      "Epoch 97/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4565 - accuracy: 0.8400 - val_loss: 0.5239 - val_accuracy: 0.7725\n",
      "Epoch 98/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4552 - accuracy: 0.8400 - val_loss: 0.5225 - val_accuracy: 0.7738\n",
      "Epoch 99/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4539 - accuracy: 0.8350 - val_loss: 0.5211 - val_accuracy: 0.7750\n",
      "Epoch 100/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.4529 - accuracy: 0.8350 - val_loss: 0.5177 - val_accuracy: 0.7825\n",
      "Epoch 101/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4515 - accuracy: 0.8300 - val_loss: 0.5163 - val_accuracy: 0.7875\n",
      "Epoch 102/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4507 - accuracy: 0.8350 - val_loss: 0.5160 - val_accuracy: 0.7850\n",
      "Epoch 103/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4493 - accuracy: 0.8400 - val_loss: 0.5146 - val_accuracy: 0.7875\n",
      "Epoch 104/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.4489 - accuracy: 0.8400 - val_loss: 0.5133 - val_accuracy: 0.7887\n",
      "Epoch 105/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.4468 - accuracy: 0.8350 - val_loss: 0.5107 - val_accuracy: 0.7887\n",
      "Epoch 106/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.4454 - accuracy: 0.8400 - val_loss: 0.5104 - val_accuracy: 0.7862\n",
      "Epoch 107/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4443 - accuracy: 0.8500 - val_loss: 0.5104 - val_accuracy: 0.7763\n",
      "Epoch 108/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4431 - accuracy: 0.8500 - val_loss: 0.5099 - val_accuracy: 0.7788\n",
      "Epoch 109/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.4416 - accuracy: 0.8450 - val_loss: 0.5083 - val_accuracy: 0.7837\n",
      "Epoch 110/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4405 - accuracy: 0.8450 - val_loss: 0.5082 - val_accuracy: 0.7775\n",
      "Epoch 111/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4401 - accuracy: 0.8450 - val_loss: 0.5067 - val_accuracy: 0.7862\n",
      "Epoch 112/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.4378 - accuracy: 0.8450 - val_loss: 0.5066 - val_accuracy: 0.7850\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 79us/step - loss: 0.4367 - accuracy: 0.8450 - val_loss: 0.5062 - val_accuracy: 0.7800\n",
      "Epoch 114/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4358 - accuracy: 0.8500 - val_loss: 0.5047 - val_accuracy: 0.7837\n",
      "Epoch 115/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4347 - accuracy: 0.8500 - val_loss: 0.5030 - val_accuracy: 0.7862\n",
      "Epoch 116/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.4335 - accuracy: 0.8450 - val_loss: 0.5008 - val_accuracy: 0.7912\n",
      "Epoch 117/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4333 - accuracy: 0.8400 - val_loss: 0.4995 - val_accuracy: 0.7900\n",
      "Epoch 118/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4316 - accuracy: 0.8450 - val_loss: 0.4999 - val_accuracy: 0.7912\n",
      "Epoch 119/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4307 - accuracy: 0.8500 - val_loss: 0.5002 - val_accuracy: 0.7937\n",
      "Epoch 120/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.4293 - accuracy: 0.8500 - val_loss: 0.4998 - val_accuracy: 0.7925\n",
      "Epoch 121/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4287 - accuracy: 0.8500 - val_loss: 0.4992 - val_accuracy: 0.7912\n",
      "Epoch 122/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.4269 - accuracy: 0.8550 - val_loss: 0.5003 - val_accuracy: 0.7862\n",
      "Epoch 123/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.4266 - accuracy: 0.8600 - val_loss: 0.5014 - val_accuracy: 0.7800\n",
      "Epoch 124/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4267 - accuracy: 0.8600 - val_loss: 0.5014 - val_accuracy: 0.7812\n",
      "Epoch 125/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4251 - accuracy: 0.8600 - val_loss: 0.4991 - val_accuracy: 0.7875\n",
      "Epoch 126/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.4232 - accuracy: 0.8500 - val_loss: 0.4975 - val_accuracy: 0.7925\n",
      "Epoch 127/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.4217 - accuracy: 0.8500 - val_loss: 0.4957 - val_accuracy: 0.7912\n",
      "Epoch 128/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.4207 - accuracy: 0.8500 - val_loss: 0.4939 - val_accuracy: 0.7950\n",
      "Epoch 129/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4200 - accuracy: 0.8500 - val_loss: 0.4941 - val_accuracy: 0.7925\n",
      "Epoch 130/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.4187 - accuracy: 0.8550 - val_loss: 0.4934 - val_accuracy: 0.7887\n",
      "Epoch 131/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.4187 - accuracy: 0.8600 - val_loss: 0.4933 - val_accuracy: 0.7887\n",
      "Epoch 132/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4173 - accuracy: 0.8500 - val_loss: 0.4917 - val_accuracy: 0.7900\n",
      "Epoch 133/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4163 - accuracy: 0.8550 - val_loss: 0.4897 - val_accuracy: 0.7912\n",
      "Epoch 134/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.4154 - accuracy: 0.8550 - val_loss: 0.4889 - val_accuracy: 0.7950\n",
      "Epoch 135/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4159 - accuracy: 0.8600 - val_loss: 0.4886 - val_accuracy: 0.7962\n",
      "Epoch 136/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.4142 - accuracy: 0.8500 - val_loss: 0.4873 - val_accuracy: 0.7925\n",
      "Epoch 137/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4130 - accuracy: 0.8550 - val_loss: 0.4866 - val_accuracy: 0.7937\n",
      "Epoch 138/500\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.4116 - accuracy: 0.8600 - val_loss: 0.4870 - val_accuracy: 0.7950\n",
      "Epoch 139/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.4104 - accuracy: 0.8550 - val_loss: 0.4864 - val_accuracy: 0.7950\n",
      "Epoch 140/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.4096 - accuracy: 0.8550 - val_loss: 0.4857 - val_accuracy: 0.7937\n",
      "Epoch 141/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.4086 - accuracy: 0.8550 - val_loss: 0.4846 - val_accuracy: 0.7937\n",
      "Epoch 142/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.4078 - accuracy: 0.8600 - val_loss: 0.4843 - val_accuracy: 0.7950\n",
      "Epoch 143/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4072 - accuracy: 0.8650 - val_loss: 0.4824 - val_accuracy: 0.7950\n",
      "Epoch 144/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.4063 - accuracy: 0.8600 - val_loss: 0.4831 - val_accuracy: 0.7937\n",
      "Epoch 145/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4056 - accuracy: 0.8550 - val_loss: 0.4825 - val_accuracy: 0.7925\n",
      "Epoch 146/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.4046 - accuracy: 0.8550 - val_loss: 0.4807 - val_accuracy: 0.7937\n",
      "Epoch 147/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4031 - accuracy: 0.8600 - val_loss: 0.4801 - val_accuracy: 0.7937\n",
      "Epoch 148/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.4021 - accuracy: 0.8600 - val_loss: 0.4806 - val_accuracy: 0.7950\n",
      "Epoch 149/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4014 - accuracy: 0.8550 - val_loss: 0.4803 - val_accuracy: 0.7925\n",
      "Epoch 150/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4010 - accuracy: 0.8600 - val_loss: 0.4786 - val_accuracy: 0.8050\n",
      "Epoch 151/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4011 - accuracy: 0.8600 - val_loss: 0.4778 - val_accuracy: 0.8075\n",
      "Epoch 152/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.4000 - accuracy: 0.8600 - val_loss: 0.4782 - val_accuracy: 0.8000\n",
      "Epoch 153/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3985 - accuracy: 0.8650 - val_loss: 0.4786 - val_accuracy: 0.7975\n",
      "Epoch 154/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3974 - accuracy: 0.8550 - val_loss: 0.4787 - val_accuracy: 0.7937\n",
      "Epoch 155/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3965 - accuracy: 0.8550 - val_loss: 0.4783 - val_accuracy: 0.7937\n",
      "Epoch 156/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3957 - accuracy: 0.8550 - val_loss: 0.4765 - val_accuracy: 0.7925\n",
      "Epoch 157/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3946 - accuracy: 0.8600 - val_loss: 0.4744 - val_accuracy: 0.7937\n",
      "Epoch 158/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3941 - accuracy: 0.8600 - val_loss: 0.4725 - val_accuracy: 0.7950\n",
      "Epoch 159/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3932 - accuracy: 0.8600 - val_loss: 0.4710 - val_accuracy: 0.8025\n",
      "Epoch 160/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3928 - accuracy: 0.8600 - val_loss: 0.4699 - val_accuracy: 0.8012\n",
      "Epoch 161/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3918 - accuracy: 0.8600 - val_loss: 0.4695 - val_accuracy: 0.8050\n",
      "Epoch 162/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3908 - accuracy: 0.8700 - val_loss: 0.4699 - val_accuracy: 0.8050\n",
      "Epoch 163/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3897 - accuracy: 0.8700 - val_loss: 0.4706 - val_accuracy: 0.8037\n",
      "Epoch 164/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3893 - accuracy: 0.8700 - val_loss: 0.4709 - val_accuracy: 0.8037\n",
      "Epoch 165/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3892 - accuracy: 0.8650 - val_loss: 0.4697 - val_accuracy: 0.8050\n",
      "Epoch 166/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3877 - accuracy: 0.8650 - val_loss: 0.4675 - val_accuracy: 0.8050\n",
      "Epoch 167/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3869 - accuracy: 0.8700 - val_loss: 0.4665 - val_accuracy: 0.8050\n",
      "Epoch 168/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3860 - accuracy: 0.8700 - val_loss: 0.4662 - val_accuracy: 0.8062\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 86us/step - loss: 0.3862 - accuracy: 0.8700 - val_loss: 0.4653 - val_accuracy: 0.8062\n",
      "Epoch 170/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3851 - accuracy: 0.8700 - val_loss: 0.4651 - val_accuracy: 0.8050\n",
      "Epoch 171/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3846 - accuracy: 0.8700 - val_loss: 0.4644 - val_accuracy: 0.8037\n",
      "Epoch 172/500\n",
      "200/200 [==============================] - 0s 69us/step - loss: 0.3835 - accuracy: 0.8700 - val_loss: 0.4645 - val_accuracy: 0.8062\n",
      "Epoch 173/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3829 - accuracy: 0.8650 - val_loss: 0.4665 - val_accuracy: 0.8075\n",
      "Epoch 174/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3817 - accuracy: 0.8650 - val_loss: 0.4661 - val_accuracy: 0.8087\n",
      "Epoch 175/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3811 - accuracy: 0.8650 - val_loss: 0.4658 - val_accuracy: 0.8087\n",
      "Epoch 176/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3806 - accuracy: 0.8700 - val_loss: 0.4648 - val_accuracy: 0.8062\n",
      "Epoch 177/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3804 - accuracy: 0.8650 - val_loss: 0.4642 - val_accuracy: 0.8050\n",
      "Epoch 178/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3791 - accuracy: 0.8700 - val_loss: 0.4635 - val_accuracy: 0.8075\n",
      "Epoch 179/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3788 - accuracy: 0.8700 - val_loss: 0.4633 - val_accuracy: 0.8075\n",
      "Epoch 180/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3781 - accuracy: 0.8700 - val_loss: 0.4632 - val_accuracy: 0.8050\n",
      "Epoch 181/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3780 - accuracy: 0.8700 - val_loss: 0.4645 - val_accuracy: 0.8037\n",
      "Epoch 182/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3769 - accuracy: 0.8700 - val_loss: 0.4641 - val_accuracy: 0.8062\n",
      "Epoch 183/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3765 - accuracy: 0.8700 - val_loss: 0.4629 - val_accuracy: 0.8050\n",
      "Epoch 184/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3754 - accuracy: 0.8700 - val_loss: 0.4613 - val_accuracy: 0.8075\n",
      "Epoch 185/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3751 - accuracy: 0.8700 - val_loss: 0.4599 - val_accuracy: 0.8062\n",
      "Epoch 186/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3747 - accuracy: 0.8650 - val_loss: 0.4600 - val_accuracy: 0.8062\n",
      "Epoch 187/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3741 - accuracy: 0.8650 - val_loss: 0.4597 - val_accuracy: 0.8062\n",
      "Epoch 188/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3733 - accuracy: 0.8700 - val_loss: 0.4603 - val_accuracy: 0.8062\n",
      "Epoch 189/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3727 - accuracy: 0.8700 - val_loss: 0.4605 - val_accuracy: 0.8075\n",
      "Epoch 190/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3722 - accuracy: 0.8700 - val_loss: 0.4596 - val_accuracy: 0.8075\n",
      "Epoch 191/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3717 - accuracy: 0.8650 - val_loss: 0.4598 - val_accuracy: 0.8075\n",
      "Epoch 192/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3719 - accuracy: 0.8650 - val_loss: 0.4593 - val_accuracy: 0.8037\n",
      "Epoch 193/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3716 - accuracy: 0.8700 - val_loss: 0.4604 - val_accuracy: 0.8050\n",
      "Epoch 194/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3705 - accuracy: 0.8650 - val_loss: 0.4581 - val_accuracy: 0.8087\n",
      "Epoch 195/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3699 - accuracy: 0.8650 - val_loss: 0.4574 - val_accuracy: 0.8087\n",
      "Epoch 196/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3696 - accuracy: 0.8650 - val_loss: 0.4562 - val_accuracy: 0.8075\n",
      "Epoch 197/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3684 - accuracy: 0.8700 - val_loss: 0.4560 - val_accuracy: 0.8087\n",
      "Epoch 198/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3677 - accuracy: 0.8700 - val_loss: 0.4570 - val_accuracy: 0.8062\n",
      "Epoch 199/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3676 - accuracy: 0.8700 - val_loss: 0.4561 - val_accuracy: 0.8075\n",
      "Epoch 200/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3667 - accuracy: 0.8700 - val_loss: 0.4556 - val_accuracy: 0.8075\n",
      "Epoch 201/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3662 - accuracy: 0.8700 - val_loss: 0.4541 - val_accuracy: 0.8075\n",
      "Epoch 202/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3661 - accuracy: 0.8700 - val_loss: 0.4512 - val_accuracy: 0.8112\n",
      "Epoch 203/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3656 - accuracy: 0.8700 - val_loss: 0.4497 - val_accuracy: 0.8138\n",
      "Epoch 204/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3650 - accuracy: 0.8650 - val_loss: 0.4495 - val_accuracy: 0.8112\n",
      "Epoch 205/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3643 - accuracy: 0.8650 - val_loss: 0.4499 - val_accuracy: 0.8087\n",
      "Epoch 206/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3641 - accuracy: 0.8700 - val_loss: 0.4524 - val_accuracy: 0.8062\n",
      "Epoch 207/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3639 - accuracy: 0.8700 - val_loss: 0.4536 - val_accuracy: 0.8100\n",
      "Epoch 208/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3629 - accuracy: 0.8700 - val_loss: 0.4531 - val_accuracy: 0.8100\n",
      "Epoch 209/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3625 - accuracy: 0.8650 - val_loss: 0.4539 - val_accuracy: 0.8087\n",
      "Epoch 210/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3619 - accuracy: 0.8650 - val_loss: 0.4528 - val_accuracy: 0.8100\n",
      "Epoch 211/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3613 - accuracy: 0.8650 - val_loss: 0.4523 - val_accuracy: 0.8087\n",
      "Epoch 212/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3615 - accuracy: 0.8650 - val_loss: 0.4520 - val_accuracy: 0.8112\n",
      "Epoch 213/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3608 - accuracy: 0.8650 - val_loss: 0.4514 - val_accuracy: 0.8112\n",
      "Epoch 214/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3605 - accuracy: 0.8650 - val_loss: 0.4502 - val_accuracy: 0.8112\n",
      "Epoch 215/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3601 - accuracy: 0.8650 - val_loss: 0.4479 - val_accuracy: 0.8112\n",
      "Epoch 216/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3593 - accuracy: 0.8650 - val_loss: 0.4471 - val_accuracy: 0.8112\n",
      "Epoch 217/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3593 - accuracy: 0.8650 - val_loss: 0.4477 - val_accuracy: 0.8112\n",
      "Epoch 218/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3583 - accuracy: 0.8650 - val_loss: 0.4475 - val_accuracy: 0.8100\n",
      "Epoch 219/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3585 - accuracy: 0.8700 - val_loss: 0.4471 - val_accuracy: 0.8087\n",
      "Epoch 220/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3576 - accuracy: 0.8700 - val_loss: 0.4462 - val_accuracy: 0.8112\n",
      "Epoch 221/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3564 - accuracy: 0.8650 - val_loss: 0.4474 - val_accuracy: 0.8100\n",
      "Epoch 222/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3570 - accuracy: 0.8750 - val_loss: 0.4481 - val_accuracy: 0.8075\n",
      "Epoch 223/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3581 - accuracy: 0.8800 - val_loss: 0.4465 - val_accuracy: 0.8100\n",
      "Epoch 224/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3563 - accuracy: 0.8800 - val_loss: 0.4462 - val_accuracy: 0.8087\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 76us/step - loss: 0.3559 - accuracy: 0.8800 - val_loss: 0.4465 - val_accuracy: 0.8075\n",
      "Epoch 226/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3545 - accuracy: 0.8750 - val_loss: 0.4462 - val_accuracy: 0.8112\n",
      "Epoch 227/500\n",
      "200/200 [==============================] - 0s 91us/step - loss: 0.3547 - accuracy: 0.8700 - val_loss: 0.4467 - val_accuracy: 0.8100\n",
      "Epoch 228/500\n",
      "200/200 [==============================] - 0s 91us/step - loss: 0.3545 - accuracy: 0.8750 - val_loss: 0.4468 - val_accuracy: 0.8087\n",
      "Epoch 229/500\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.3538 - accuracy: 0.8750 - val_loss: 0.4453 - val_accuracy: 0.8112\n",
      "Epoch 230/500\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.3530 - accuracy: 0.8650 - val_loss: 0.4454 - val_accuracy: 0.8100\n",
      "Epoch 231/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3528 - accuracy: 0.8650 - val_loss: 0.4450 - val_accuracy: 0.8100\n",
      "Epoch 232/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3525 - accuracy: 0.8650 - val_loss: 0.4443 - val_accuracy: 0.8138\n",
      "Epoch 233/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3525 - accuracy: 0.8700 - val_loss: 0.4441 - val_accuracy: 0.8138\n",
      "Epoch 234/500\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.3519 - accuracy: 0.8650 - val_loss: 0.4449 - val_accuracy: 0.8100\n",
      "Epoch 235/500\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.3516 - accuracy: 0.8650 - val_loss: 0.4448 - val_accuracy: 0.8100\n",
      "Epoch 236/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.3507 - accuracy: 0.8650 - val_loss: 0.4447 - val_accuracy: 0.8100\n",
      "Epoch 237/500\n",
      "200/200 [==============================] - 0s 90us/step - loss: 0.3507 - accuracy: 0.8700 - val_loss: 0.4442 - val_accuracy: 0.8100\n",
      "Epoch 238/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3505 - accuracy: 0.8700 - val_loss: 0.4435 - val_accuracy: 0.8112\n",
      "Epoch 239/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3498 - accuracy: 0.8650 - val_loss: 0.4434 - val_accuracy: 0.8112\n",
      "Epoch 240/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3493 - accuracy: 0.8650 - val_loss: 0.4443 - val_accuracy: 0.8087\n",
      "Epoch 241/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3491 - accuracy: 0.8750 - val_loss: 0.4449 - val_accuracy: 0.8112\n",
      "Epoch 242/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3484 - accuracy: 0.8750 - val_loss: 0.4441 - val_accuracy: 0.8138\n",
      "Epoch 243/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3486 - accuracy: 0.8750 - val_loss: 0.4436 - val_accuracy: 0.8138\n",
      "Epoch 244/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3480 - accuracy: 0.8750 - val_loss: 0.4435 - val_accuracy: 0.8100\n",
      "Epoch 245/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3482 - accuracy: 0.8650 - val_loss: 0.4448 - val_accuracy: 0.8125\n",
      "Epoch 246/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3473 - accuracy: 0.8650 - val_loss: 0.4441 - val_accuracy: 0.8125\n",
      "Epoch 247/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.3471 - accuracy: 0.8650 - val_loss: 0.4443 - val_accuracy: 0.8100\n",
      "Epoch 248/500\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.3468 - accuracy: 0.8700 - val_loss: 0.4433 - val_accuracy: 0.8112\n",
      "Epoch 249/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3462 - accuracy: 0.8650 - val_loss: 0.4415 - val_accuracy: 0.8112\n",
      "Epoch 250/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3462 - accuracy: 0.8650 - val_loss: 0.4414 - val_accuracy: 0.8138\n",
      "Epoch 251/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3456 - accuracy: 0.8750 - val_loss: 0.4417 - val_accuracy: 0.8112\n",
      "Epoch 252/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3451 - accuracy: 0.8750 - val_loss: 0.4411 - val_accuracy: 0.8112\n",
      "Epoch 253/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3449 - accuracy: 0.8750 - val_loss: 0.4414 - val_accuracy: 0.8125\n",
      "Epoch 254/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3445 - accuracy: 0.8650 - val_loss: 0.4417 - val_accuracy: 0.8112\n",
      "Epoch 255/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3443 - accuracy: 0.8650 - val_loss: 0.4432 - val_accuracy: 0.8112\n",
      "Epoch 256/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3444 - accuracy: 0.8700 - val_loss: 0.4443 - val_accuracy: 0.8125\n",
      "Epoch 257/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3438 - accuracy: 0.8650 - val_loss: 0.4429 - val_accuracy: 0.8138\n",
      "Epoch 258/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3432 - accuracy: 0.8750 - val_loss: 0.4422 - val_accuracy: 0.8125\n",
      "Epoch 259/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3426 - accuracy: 0.8750 - val_loss: 0.4410 - val_accuracy: 0.8150\n",
      "Epoch 260/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3436 - accuracy: 0.8800 - val_loss: 0.4423 - val_accuracy: 0.8125\n",
      "Epoch 261/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3439 - accuracy: 0.8800 - val_loss: 0.4421 - val_accuracy: 0.8163\n",
      "Epoch 262/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3429 - accuracy: 0.8800 - val_loss: 0.4438 - val_accuracy: 0.8138\n",
      "Epoch 263/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3419 - accuracy: 0.8800 - val_loss: 0.4444 - val_accuracy: 0.8150\n",
      "Epoch 264/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3422 - accuracy: 0.8700 - val_loss: 0.4441 - val_accuracy: 0.8112\n",
      "Epoch 265/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3414 - accuracy: 0.8650 - val_loss: 0.4455 - val_accuracy: 0.8125\n",
      "Epoch 266/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3415 - accuracy: 0.8700 - val_loss: 0.4470 - val_accuracy: 0.8125\n",
      "Epoch 267/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3417 - accuracy: 0.8700 - val_loss: 0.4464 - val_accuracy: 0.8138\n",
      "Epoch 268/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3416 - accuracy: 0.8700 - val_loss: 0.4474 - val_accuracy: 0.8138\n",
      "Epoch 269/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3414 - accuracy: 0.8700 - val_loss: 0.4446 - val_accuracy: 0.8125\n",
      "Epoch 270/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3402 - accuracy: 0.8650 - val_loss: 0.4429 - val_accuracy: 0.8138\n",
      "Epoch 271/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3401 - accuracy: 0.8700 - val_loss: 0.4398 - val_accuracy: 0.8125\n",
      "Epoch 272/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3389 - accuracy: 0.8750 - val_loss: 0.4393 - val_accuracy: 0.8150\n",
      "Epoch 273/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3382 - accuracy: 0.8750 - val_loss: 0.4388 - val_accuracy: 0.8125\n",
      "Epoch 274/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3384 - accuracy: 0.8750 - val_loss: 0.4377 - val_accuracy: 0.8188\n",
      "Epoch 275/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3387 - accuracy: 0.8800 - val_loss: 0.4363 - val_accuracy: 0.8188\n",
      "Epoch 276/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3380 - accuracy: 0.8800 - val_loss: 0.4364 - val_accuracy: 0.8188\n",
      "Epoch 277/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3374 - accuracy: 0.8750 - val_loss: 0.4371 - val_accuracy: 0.8100\n",
      "Epoch 278/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3366 - accuracy: 0.8750 - val_loss: 0.4387 - val_accuracy: 0.8112\n",
      "Epoch 279/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3364 - accuracy: 0.8750 - val_loss: 0.4408 - val_accuracy: 0.8112\n",
      "Epoch 280/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3369 - accuracy: 0.8750 - val_loss: 0.4423 - val_accuracy: 0.8112\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 76us/step - loss: 0.3367 - accuracy: 0.8750 - val_loss: 0.4390 - val_accuracy: 0.8138\n",
      "Epoch 282/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3355 - accuracy: 0.8800 - val_loss: 0.4375 - val_accuracy: 0.8150\n",
      "Epoch 283/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3355 - accuracy: 0.8800 - val_loss: 0.4374 - val_accuracy: 0.8163\n",
      "Epoch 284/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3352 - accuracy: 0.8800 - val_loss: 0.4371 - val_accuracy: 0.8150\n",
      "Epoch 285/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3347 - accuracy: 0.8800 - val_loss: 0.4375 - val_accuracy: 0.8125\n",
      "Epoch 286/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3344 - accuracy: 0.8750 - val_loss: 0.4385 - val_accuracy: 0.8112\n",
      "Epoch 287/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3341 - accuracy: 0.8750 - val_loss: 0.4418 - val_accuracy: 0.8138\n",
      "Epoch 288/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3343 - accuracy: 0.8750 - val_loss: 0.4435 - val_accuracy: 0.8138\n",
      "Epoch 289/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3353 - accuracy: 0.8700 - val_loss: 0.4443 - val_accuracy: 0.8138\n",
      "Epoch 290/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3349 - accuracy: 0.8750 - val_loss: 0.4428 - val_accuracy: 0.8150\n",
      "Epoch 291/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3339 - accuracy: 0.8750 - val_loss: 0.4411 - val_accuracy: 0.8150\n",
      "Epoch 292/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3336 - accuracy: 0.8750 - val_loss: 0.4404 - val_accuracy: 0.8138\n",
      "Epoch 293/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3332 - accuracy: 0.8750 - val_loss: 0.4402 - val_accuracy: 0.8125\n",
      "Epoch 294/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3330 - accuracy: 0.8750 - val_loss: 0.4396 - val_accuracy: 0.8125\n",
      "Epoch 295/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3324 - accuracy: 0.8700 - val_loss: 0.4396 - val_accuracy: 0.8125\n",
      "Epoch 296/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3320 - accuracy: 0.8750 - val_loss: 0.4394 - val_accuracy: 0.8138\n",
      "Epoch 297/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3313 - accuracy: 0.8750 - val_loss: 0.4401 - val_accuracy: 0.8125\n",
      "Epoch 298/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3317 - accuracy: 0.8750 - val_loss: 0.4407 - val_accuracy: 0.8125\n",
      "Epoch 299/500\n",
      "200/200 [==============================] - 0s 69us/step - loss: 0.3312 - accuracy: 0.8750 - val_loss: 0.4418 - val_accuracy: 0.8138\n",
      "Epoch 300/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3311 - accuracy: 0.8750 - val_loss: 0.4417 - val_accuracy: 0.8138\n",
      "Epoch 301/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3304 - accuracy: 0.8750 - val_loss: 0.4392 - val_accuracy: 0.8150\n",
      "Epoch 302/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3303 - accuracy: 0.8750 - val_loss: 0.4372 - val_accuracy: 0.8150\n",
      "Epoch 303/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3304 - accuracy: 0.8800 - val_loss: 0.4367 - val_accuracy: 0.8200\n",
      "Epoch 304/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3307 - accuracy: 0.8800 - val_loss: 0.4368 - val_accuracy: 0.8213\n",
      "Epoch 305/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3308 - accuracy: 0.8800 - val_loss: 0.4374 - val_accuracy: 0.8213\n",
      "Epoch 306/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3300 - accuracy: 0.8800 - val_loss: 0.4371 - val_accuracy: 0.8175\n",
      "Epoch 307/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3290 - accuracy: 0.8800 - val_loss: 0.4374 - val_accuracy: 0.8150\n",
      "Epoch 308/500\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.3289 - accuracy: 0.8750 - val_loss: 0.4386 - val_accuracy: 0.8163\n",
      "Epoch 309/500\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.3286 - accuracy: 0.8750 - val_loss: 0.4387 - val_accuracy: 0.8163\n",
      "Epoch 310/500\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.3282 - accuracy: 0.8800 - val_loss: 0.4394 - val_accuracy: 0.8175\n",
      "Epoch 311/500\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.3280 - accuracy: 0.8800 - val_loss: 0.4407 - val_accuracy: 0.8150\n",
      "Epoch 312/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.3284 - accuracy: 0.8800 - val_loss: 0.4407 - val_accuracy: 0.8188\n",
      "Epoch 313/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3283 - accuracy: 0.8750 - val_loss: 0.4383 - val_accuracy: 0.8175\n",
      "Epoch 314/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3276 - accuracy: 0.8750 - val_loss: 0.4389 - val_accuracy: 0.8175\n",
      "Epoch 315/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3278 - accuracy: 0.8750 - val_loss: 0.4379 - val_accuracy: 0.8150\n",
      "Epoch 316/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3269 - accuracy: 0.8750 - val_loss: 0.4387 - val_accuracy: 0.8150\n",
      "Epoch 317/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3266 - accuracy: 0.8750 - val_loss: 0.4405 - val_accuracy: 0.8150\n",
      "Epoch 318/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3265 - accuracy: 0.8800 - val_loss: 0.4401 - val_accuracy: 0.8163\n",
      "Epoch 319/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3264 - accuracy: 0.8800 - val_loss: 0.4406 - val_accuracy: 0.8163\n",
      "Epoch 320/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3259 - accuracy: 0.8800 - val_loss: 0.4407 - val_accuracy: 0.8163\n",
      "Epoch 321/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3260 - accuracy: 0.8750 - val_loss: 0.4411 - val_accuracy: 0.8150\n",
      "Epoch 322/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3260 - accuracy: 0.8750 - val_loss: 0.4409 - val_accuracy: 0.8138\n",
      "Epoch 323/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3260 - accuracy: 0.8750 - val_loss: 0.4384 - val_accuracy: 0.8163\n",
      "Epoch 324/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3256 - accuracy: 0.8800 - val_loss: 0.4365 - val_accuracy: 0.8175\n",
      "Epoch 325/500\n",
      "200/200 [==============================] - 0s 90us/step - loss: 0.3259 - accuracy: 0.8800 - val_loss: 0.4362 - val_accuracy: 0.8213\n",
      "Epoch 326/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3254 - accuracy: 0.8800 - val_loss: 0.4370 - val_accuracy: 0.8200\n",
      "Epoch 327/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3244 - accuracy: 0.8800 - val_loss: 0.4371 - val_accuracy: 0.8225\n",
      "Epoch 328/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3243 - accuracy: 0.8800 - val_loss: 0.4377 - val_accuracy: 0.8225\n",
      "Epoch 329/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3249 - accuracy: 0.8750 - val_loss: 0.4385 - val_accuracy: 0.8213\n",
      "Epoch 330/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3243 - accuracy: 0.8750 - val_loss: 0.4391 - val_accuracy: 0.8213\n",
      "Epoch 331/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3251 - accuracy: 0.8750 - val_loss: 0.4385 - val_accuracy: 0.8200\n",
      "Epoch 332/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3245 - accuracy: 0.8800 - val_loss: 0.4379 - val_accuracy: 0.8200\n",
      "Epoch 333/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3230 - accuracy: 0.8800 - val_loss: 0.4393 - val_accuracy: 0.8175\n",
      "Epoch 334/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3228 - accuracy: 0.8800 - val_loss: 0.4396 - val_accuracy: 0.8150\n",
      "Epoch 335/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3225 - accuracy: 0.8800 - val_loss: 0.4398 - val_accuracy: 0.8163\n",
      "Epoch 336/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3221 - accuracy: 0.8800 - val_loss: 0.4391 - val_accuracy: 0.8175\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 77us/step - loss: 0.3221 - accuracy: 0.8800 - val_loss: 0.4393 - val_accuracy: 0.8200\n",
      "Epoch 338/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3221 - accuracy: 0.8800 - val_loss: 0.4390 - val_accuracy: 0.8175\n",
      "Epoch 339/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3226 - accuracy: 0.8800 - val_loss: 0.4397 - val_accuracy: 0.8175\n",
      "Epoch 340/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3230 - accuracy: 0.8800 - val_loss: 0.4371 - val_accuracy: 0.8225\n",
      "Epoch 341/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3222 - accuracy: 0.8800 - val_loss: 0.4356 - val_accuracy: 0.8213\n",
      "Epoch 342/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3221 - accuracy: 0.8800 - val_loss: 0.4358 - val_accuracy: 0.8225\n",
      "Epoch 343/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3213 - accuracy: 0.8800 - val_loss: 0.4363 - val_accuracy: 0.8213\n",
      "Epoch 344/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3218 - accuracy: 0.8800 - val_loss: 0.4375 - val_accuracy: 0.8225\n",
      "Epoch 345/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3212 - accuracy: 0.8800 - val_loss: 0.4382 - val_accuracy: 0.8163\n",
      "Epoch 346/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3205 - accuracy: 0.8750 - val_loss: 0.4364 - val_accuracy: 0.8188\n",
      "Epoch 347/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3209 - accuracy: 0.8750 - val_loss: 0.4355 - val_accuracy: 0.8200\n",
      "Epoch 348/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3209 - accuracy: 0.8800 - val_loss: 0.4353 - val_accuracy: 0.8225\n",
      "Epoch 349/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3197 - accuracy: 0.8800 - val_loss: 0.4346 - val_accuracy: 0.8200\n",
      "Epoch 350/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3206 - accuracy: 0.8800 - val_loss: 0.4335 - val_accuracy: 0.8200\n",
      "Epoch 351/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3202 - accuracy: 0.8800 - val_loss: 0.4337 - val_accuracy: 0.8213\n",
      "Epoch 352/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3199 - accuracy: 0.8750 - val_loss: 0.4333 - val_accuracy: 0.8200\n",
      "Epoch 353/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3198 - accuracy: 0.8750 - val_loss: 0.4332 - val_accuracy: 0.8200\n",
      "Epoch 354/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3195 - accuracy: 0.8750 - val_loss: 0.4353 - val_accuracy: 0.8175\n",
      "Epoch 355/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3188 - accuracy: 0.8800 - val_loss: 0.4358 - val_accuracy: 0.8175\n",
      "Epoch 356/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.3186 - accuracy: 0.8800 - val_loss: 0.4359 - val_accuracy: 0.8200\n",
      "Epoch 357/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3185 - accuracy: 0.8800 - val_loss: 0.4356 - val_accuracy: 0.8188\n",
      "Epoch 358/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3181 - accuracy: 0.8800 - val_loss: 0.4348 - val_accuracy: 0.8238\n",
      "Epoch 359/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3183 - accuracy: 0.8800 - val_loss: 0.4357 - val_accuracy: 0.8250\n",
      "Epoch 360/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3179 - accuracy: 0.8800 - val_loss: 0.4363 - val_accuracy: 0.8225\n",
      "Epoch 361/500\n",
      "200/200 [==============================] - 0s 95us/step - loss: 0.3180 - accuracy: 0.8800 - val_loss: 0.4354 - val_accuracy: 0.8263\n",
      "Epoch 362/500\n",
      "200/200 [==============================] - 0s 96us/step - loss: 0.3178 - accuracy: 0.8800 - val_loss: 0.4359 - val_accuracy: 0.8238\n",
      "Epoch 363/500\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.3172 - accuracy: 0.8750 - val_loss: 0.4356 - val_accuracy: 0.8225\n",
      "Epoch 364/500\n",
      "200/200 [==============================] - 0s 98us/step - loss: 0.3176 - accuracy: 0.8800 - val_loss: 0.4363 - val_accuracy: 0.8188\n",
      "Epoch 365/500\n",
      "200/200 [==============================] - 0s 95us/step - loss: 0.3173 - accuracy: 0.8750 - val_loss: 0.4351 - val_accuracy: 0.8238\n",
      "Epoch 366/500\n",
      "200/200 [==============================] - 0s 95us/step - loss: 0.3175 - accuracy: 0.8750 - val_loss: 0.4345 - val_accuracy: 0.8225\n",
      "Epoch 367/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3167 - accuracy: 0.8750 - val_loss: 0.4345 - val_accuracy: 0.8213\n",
      "Epoch 368/500\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.3175 - accuracy: 0.8750 - val_loss: 0.4359 - val_accuracy: 0.8188\n",
      "Epoch 369/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3175 - accuracy: 0.8750 - val_loss: 0.4368 - val_accuracy: 0.8188\n",
      "Epoch 370/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3166 - accuracy: 0.8750 - val_loss: 0.4384 - val_accuracy: 0.8200\n",
      "Epoch 371/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3168 - accuracy: 0.8800 - val_loss: 0.4401 - val_accuracy: 0.8188\n",
      "Epoch 372/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3168 - accuracy: 0.8850 - val_loss: 0.4402 - val_accuracy: 0.8163\n",
      "Epoch 373/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3167 - accuracy: 0.8850 - val_loss: 0.4408 - val_accuracy: 0.8188\n",
      "Epoch 374/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3158 - accuracy: 0.8850 - val_loss: 0.4413 - val_accuracy: 0.8175\n",
      "Epoch 375/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3158 - accuracy: 0.8850 - val_loss: 0.4427 - val_accuracy: 0.8200\n",
      "Epoch 376/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3163 - accuracy: 0.8800 - val_loss: 0.4423 - val_accuracy: 0.8200\n",
      "Epoch 377/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3156 - accuracy: 0.8800 - val_loss: 0.4406 - val_accuracy: 0.8175\n",
      "Epoch 378/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3153 - accuracy: 0.8850 - val_loss: 0.4417 - val_accuracy: 0.8163\n",
      "Epoch 379/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3149 - accuracy: 0.8850 - val_loss: 0.4406 - val_accuracy: 0.8163\n",
      "Epoch 380/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3151 - accuracy: 0.8800 - val_loss: 0.4395 - val_accuracy: 0.8200\n",
      "Epoch 381/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3152 - accuracy: 0.8800 - val_loss: 0.4395 - val_accuracy: 0.8225\n",
      "Epoch 382/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3147 - accuracy: 0.8800 - val_loss: 0.4416 - val_accuracy: 0.8150\n",
      "Epoch 383/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3145 - accuracy: 0.8850 - val_loss: 0.4417 - val_accuracy: 0.8163\n",
      "Epoch 384/500\n",
      "200/200 [==============================] - 0s 69us/step - loss: 0.3143 - accuracy: 0.8800 - val_loss: 0.4395 - val_accuracy: 0.8200\n",
      "Epoch 385/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3145 - accuracy: 0.8800 - val_loss: 0.4391 - val_accuracy: 0.8188\n",
      "Epoch 386/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3154 - accuracy: 0.8800 - val_loss: 0.4386 - val_accuracy: 0.8213\n",
      "Epoch 387/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3153 - accuracy: 0.8800 - val_loss: 0.4381 - val_accuracy: 0.8213\n",
      "Epoch 388/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3144 - accuracy: 0.8800 - val_loss: 0.4395 - val_accuracy: 0.8200\n",
      "Epoch 389/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3138 - accuracy: 0.8800 - val_loss: 0.4401 - val_accuracy: 0.8163\n",
      "Epoch 390/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3142 - accuracy: 0.8750 - val_loss: 0.4383 - val_accuracy: 0.8188\n",
      "Epoch 391/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3143 - accuracy: 0.8800 - val_loss: 0.4365 - val_accuracy: 0.8238\n",
      "Epoch 392/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3136 - accuracy: 0.8800 - val_loss: 0.4365 - val_accuracy: 0.8213\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 77us/step - loss: 0.3142 - accuracy: 0.8800 - val_loss: 0.4366 - val_accuracy: 0.8213\n",
      "Epoch 394/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3141 - accuracy: 0.8800 - val_loss: 0.4366 - val_accuracy: 0.8238\n",
      "Epoch 395/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3137 - accuracy: 0.8800 - val_loss: 0.4365 - val_accuracy: 0.8200\n",
      "Epoch 396/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3127 - accuracy: 0.8800 - val_loss: 0.4374 - val_accuracy: 0.8188\n",
      "Epoch 397/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3127 - accuracy: 0.8800 - val_loss: 0.4380 - val_accuracy: 0.8213\n",
      "Epoch 398/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3126 - accuracy: 0.8800 - val_loss: 0.4389 - val_accuracy: 0.8150\n",
      "Epoch 399/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3117 - accuracy: 0.8800 - val_loss: 0.4384 - val_accuracy: 0.8175\n",
      "Epoch 400/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3119 - accuracy: 0.8800 - val_loss: 0.4392 - val_accuracy: 0.8175\n",
      "Epoch 401/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3122 - accuracy: 0.8850 - val_loss: 0.4409 - val_accuracy: 0.8175\n",
      "Epoch 402/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3120 - accuracy: 0.8850 - val_loss: 0.4408 - val_accuracy: 0.8188\n",
      "Epoch 403/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3125 - accuracy: 0.8850 - val_loss: 0.4422 - val_accuracy: 0.8188\n",
      "Epoch 404/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3117 - accuracy: 0.8850 - val_loss: 0.4411 - val_accuracy: 0.8200\n",
      "Epoch 405/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3115 - accuracy: 0.8850 - val_loss: 0.4396 - val_accuracy: 0.8163\n",
      "Epoch 406/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3109 - accuracy: 0.8850 - val_loss: 0.4394 - val_accuracy: 0.8163\n",
      "Epoch 407/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3109 - accuracy: 0.8800 - val_loss: 0.4381 - val_accuracy: 0.8163\n",
      "Epoch 408/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3106 - accuracy: 0.8800 - val_loss: 0.4387 - val_accuracy: 0.8200\n",
      "Epoch 409/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3101 - accuracy: 0.8800 - val_loss: 0.4390 - val_accuracy: 0.8200\n",
      "Epoch 410/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3102 - accuracy: 0.8850 - val_loss: 0.4379 - val_accuracy: 0.8200\n",
      "Epoch 411/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3098 - accuracy: 0.8800 - val_loss: 0.4381 - val_accuracy: 0.8200\n",
      "Epoch 412/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3098 - accuracy: 0.8800 - val_loss: 0.4380 - val_accuracy: 0.8213\n",
      "Epoch 413/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3097 - accuracy: 0.8850 - val_loss: 0.4387 - val_accuracy: 0.8200\n",
      "Epoch 414/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3101 - accuracy: 0.8850 - val_loss: 0.4387 - val_accuracy: 0.8163\n",
      "Epoch 415/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3094 - accuracy: 0.8800 - val_loss: 0.4389 - val_accuracy: 0.8163\n",
      "Epoch 416/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3097 - accuracy: 0.8800 - val_loss: 0.4416 - val_accuracy: 0.8138\n",
      "Epoch 417/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3092 - accuracy: 0.8800 - val_loss: 0.4422 - val_accuracy: 0.8138\n",
      "Epoch 418/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3093 - accuracy: 0.8800 - val_loss: 0.4416 - val_accuracy: 0.8150\n",
      "Epoch 419/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3094 - accuracy: 0.8800 - val_loss: 0.4407 - val_accuracy: 0.8225\n",
      "Epoch 420/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3089 - accuracy: 0.8800 - val_loss: 0.4412 - val_accuracy: 0.8213\n",
      "Epoch 421/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3090 - accuracy: 0.8850 - val_loss: 0.4426 - val_accuracy: 0.8163\n",
      "Epoch 422/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3089 - accuracy: 0.8850 - val_loss: 0.4424 - val_accuracy: 0.8188\n",
      "Epoch 423/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3092 - accuracy: 0.8850 - val_loss: 0.4429 - val_accuracy: 0.8188\n",
      "Epoch 424/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3084 - accuracy: 0.8850 - val_loss: 0.4410 - val_accuracy: 0.8163\n",
      "Epoch 425/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3080 - accuracy: 0.8800 - val_loss: 0.4403 - val_accuracy: 0.8163\n",
      "Epoch 426/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3087 - accuracy: 0.8750 - val_loss: 0.4401 - val_accuracy: 0.8188\n",
      "Epoch 427/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3094 - accuracy: 0.8750 - val_loss: 0.4414 - val_accuracy: 0.8163\n",
      "Epoch 428/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3083 - accuracy: 0.8750 - val_loss: 0.4405 - val_accuracy: 0.8175\n",
      "Epoch 429/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3081 - accuracy: 0.8750 - val_loss: 0.4408 - val_accuracy: 0.8150\n",
      "Epoch 430/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3074 - accuracy: 0.8800 - val_loss: 0.4397 - val_accuracy: 0.8188\n",
      "Epoch 431/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3075 - accuracy: 0.8800 - val_loss: 0.4402 - val_accuracy: 0.8200\n",
      "Epoch 432/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3068 - accuracy: 0.8800 - val_loss: 0.4386 - val_accuracy: 0.8200\n",
      "Epoch 433/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3070 - accuracy: 0.8750 - val_loss: 0.4395 - val_accuracy: 0.8175\n",
      "Epoch 434/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3077 - accuracy: 0.8800 - val_loss: 0.4430 - val_accuracy: 0.8213\n",
      "Epoch 435/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3074 - accuracy: 0.8850 - val_loss: 0.4417 - val_accuracy: 0.8200\n",
      "Epoch 436/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3067 - accuracy: 0.8850 - val_loss: 0.4402 - val_accuracy: 0.8175\n",
      "Epoch 437/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3065 - accuracy: 0.8800 - val_loss: 0.4401 - val_accuracy: 0.8188\n",
      "Epoch 438/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3065 - accuracy: 0.8750 - val_loss: 0.4403 - val_accuracy: 0.8163\n",
      "Epoch 439/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3064 - accuracy: 0.8750 - val_loss: 0.4403 - val_accuracy: 0.8188\n",
      "Epoch 440/500\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.3059 - accuracy: 0.8850 - val_loss: 0.4405 - val_accuracy: 0.8188\n",
      "Epoch 441/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3058 - accuracy: 0.8850 - val_loss: 0.4413 - val_accuracy: 0.8175\n",
      "Epoch 442/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3055 - accuracy: 0.8850 - val_loss: 0.4421 - val_accuracy: 0.8188\n",
      "Epoch 443/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3052 - accuracy: 0.8850 - val_loss: 0.4438 - val_accuracy: 0.8175\n",
      "Epoch 444/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3053 - accuracy: 0.8850 - val_loss: 0.4439 - val_accuracy: 0.8175\n",
      "Epoch 445/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3059 - accuracy: 0.8800 - val_loss: 0.4435 - val_accuracy: 0.8175\n",
      "Epoch 446/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3058 - accuracy: 0.8850 - val_loss: 0.4416 - val_accuracy: 0.8250\n",
      "Epoch 447/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3053 - accuracy: 0.8850 - val_loss: 0.4426 - val_accuracy: 0.8250\n",
      "Epoch 448/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3052 - accuracy: 0.8850 - val_loss: 0.4423 - val_accuracy: 0.8238\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 73us/step - loss: 0.3050 - accuracy: 0.8850 - val_loss: 0.4426 - val_accuracy: 0.8250\n",
      "Epoch 450/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3048 - accuracy: 0.8850 - val_loss: 0.4432 - val_accuracy: 0.8225\n",
      "Epoch 451/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3056 - accuracy: 0.8850 - val_loss: 0.4437 - val_accuracy: 0.8175\n",
      "Epoch 452/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3047 - accuracy: 0.8800 - val_loss: 0.4420 - val_accuracy: 0.8213\n",
      "Epoch 453/500\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.3043 - accuracy: 0.8800 - val_loss: 0.4418 - val_accuracy: 0.8238\n",
      "Epoch 454/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.4420 - val_accuracy: 0.8175\n",
      "Epoch 455/500\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.3045 - accuracy: 0.8800 - val_loss: 0.4417 - val_accuracy: 0.8188\n",
      "Epoch 456/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3038 - accuracy: 0.8800 - val_loss: 0.4419 - val_accuracy: 0.8175\n",
      "Epoch 457/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3040 - accuracy: 0.8800 - val_loss: 0.4421 - val_accuracy: 0.8163\n",
      "Epoch 458/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3034 - accuracy: 0.8850 - val_loss: 0.4449 - val_accuracy: 0.8188\n",
      "Epoch 459/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3041 - accuracy: 0.8850 - val_loss: 0.4455 - val_accuracy: 0.8163\n",
      "Epoch 460/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3044 - accuracy: 0.8900 - val_loss: 0.4461 - val_accuracy: 0.8163\n",
      "Epoch 461/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3038 - accuracy: 0.8850 - val_loss: 0.4446 - val_accuracy: 0.8188\n",
      "Epoch 462/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3033 - accuracy: 0.8850 - val_loss: 0.4443 - val_accuracy: 0.8188\n",
      "Epoch 463/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3042 - accuracy: 0.8850 - val_loss: 0.4472 - val_accuracy: 0.8163\n",
      "Epoch 464/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.3038 - accuracy: 0.8850 - val_loss: 0.4472 - val_accuracy: 0.8175\n",
      "Epoch 465/500\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.3033 - accuracy: 0.8850 - val_loss: 0.4463 - val_accuracy: 0.8188\n",
      "Epoch 466/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3031 - accuracy: 0.8850 - val_loss: 0.4448 - val_accuracy: 0.8213\n",
      "Epoch 467/500\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.3027 - accuracy: 0.8800 - val_loss: 0.4444 - val_accuracy: 0.8225\n",
      "Epoch 468/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3026 - accuracy: 0.8800 - val_loss: 0.4448 - val_accuracy: 0.8238\n",
      "Epoch 469/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3026 - accuracy: 0.8850 - val_loss: 0.4454 - val_accuracy: 0.8238\n",
      "Epoch 470/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3029 - accuracy: 0.8850 - val_loss: 0.4449 - val_accuracy: 0.8188\n",
      "Epoch 471/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3019 - accuracy: 0.8850 - val_loss: 0.4433 - val_accuracy: 0.8175\n",
      "Epoch 472/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3020 - accuracy: 0.8800 - val_loss: 0.4429 - val_accuracy: 0.8175\n",
      "Epoch 473/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3025 - accuracy: 0.8750 - val_loss: 0.4442 - val_accuracy: 0.8175\n",
      "Epoch 474/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3028 - accuracy: 0.8750 - val_loss: 0.4451 - val_accuracy: 0.8175\n",
      "Epoch 475/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3023 - accuracy: 0.8750 - val_loss: 0.4459 - val_accuracy: 0.8138\n",
      "Epoch 476/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3017 - accuracy: 0.8800 - val_loss: 0.4467 - val_accuracy: 0.8163\n",
      "Epoch 477/500\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.3021 - accuracy: 0.8850 - val_loss: 0.4464 - val_accuracy: 0.8188\n",
      "Epoch 478/500\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.3020 - accuracy: 0.8850 - val_loss: 0.4450 - val_accuracy: 0.8188\n",
      "Epoch 479/500\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.3015 - accuracy: 0.8850 - val_loss: 0.4453 - val_accuracy: 0.8200\n",
      "Epoch 480/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.3009 - accuracy: 0.8850 - val_loss: 0.4458 - val_accuracy: 0.8175\n",
      "Epoch 481/500\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.3014 - accuracy: 0.8850 - val_loss: 0.4467 - val_accuracy: 0.8188\n",
      "Epoch 482/500\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.3016 - accuracy: 0.8850 - val_loss: 0.4478 - val_accuracy: 0.8188\n",
      "Epoch 483/500\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.3019 - accuracy: 0.8800 - val_loss: 0.4465 - val_accuracy: 0.8225\n",
      "Epoch 484/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3013 - accuracy: 0.8800 - val_loss: 0.4474 - val_accuracy: 0.8188\n",
      "Epoch 485/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3018 - accuracy: 0.8800 - val_loss: 0.4469 - val_accuracy: 0.8200\n",
      "Epoch 486/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3011 - accuracy: 0.8800 - val_loss: 0.4468 - val_accuracy: 0.8200\n",
      "Epoch 487/500\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.3006 - accuracy: 0.8850 - val_loss: 0.4443 - val_accuracy: 0.8188\n",
      "Epoch 488/500\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.3003 - accuracy: 0.8850 - val_loss: 0.4448 - val_accuracy: 0.8200\n",
      "Epoch 489/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3006 - accuracy: 0.8750 - val_loss: 0.4454 - val_accuracy: 0.8163\n",
      "Epoch 490/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3022 - accuracy: 0.8800 - val_loss: 0.4472 - val_accuracy: 0.8188\n",
      "Epoch 491/500\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.3012 - accuracy: 0.8850 - val_loss: 0.4471 - val_accuracy: 0.8238\n",
      "Epoch 492/500\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.3006 - accuracy: 0.8800 - val_loss: 0.4468 - val_accuracy: 0.8213\n",
      "Epoch 493/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3002 - accuracy: 0.8800 - val_loss: 0.4482 - val_accuracy: 0.8175\n",
      "Epoch 494/500\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.3005 - accuracy: 0.8800 - val_loss: 0.4470 - val_accuracy: 0.8188\n",
      "Epoch 495/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3003 - accuracy: 0.8800 - val_loss: 0.4471 - val_accuracy: 0.8175\n",
      "Epoch 496/500\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.3003 - accuracy: 0.8850 - val_loss: 0.4469 - val_accuracy: 0.8200\n",
      "Epoch 497/500\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.3004 - accuracy: 0.8800 - val_loss: 0.4443 - val_accuracy: 0.8188\n",
      "Epoch 498/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.3002 - accuracy: 0.8800 - val_loss: 0.4436 - val_accuracy: 0.8188\n",
      "Epoch 499/500\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.2989 - accuracy: 0.8750 - val_loss: 0.4426 - val_accuracy: 0.8213\n",
      "Epoch 500/500\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.2995 - accuracy: 0.8700 - val_loss: 0.4438 - val_accuracy: 0.8150\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.875, Test: 0.815\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves of model accuracy\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning] *",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
